{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. Enter the amino acid sequence(s) to fold ⬇️\n",
    "#@markdown Enter the amino acid sequence(s) to fold:\n",
    "#@markdown * If you enter only a single sequence, the monomer model will be \n",
    "#@markdown used (unless you override this below).\n",
    "#@markdown * If you enter multiple sequences, the multimer model will be used.\n",
    "\n",
    "\n",
    "sequence_1 = 'MAAHKGAEHHHKAAEHHEQAAKHHHAAAEHHEKGEHEQAAHHADTAYAHHKHAEEHAAQAAKHDAEHHAPKPH'  #@param {type:\"string\"}\n",
    "sequence_2 = ''  #@param {type:\"string\"}\n",
    "sequence_3 = ''  #@param {type:\"string\"}\n",
    "sequence_4 = ''  #@param {type:\"string\"}\n",
    "sequence_5 = ''  #@param {type:\"string\"}\n",
    "sequence_6 = ''  #@param {type:\"string\"}\n",
    "sequence_7 = ''  #@param {type:\"string\"}\n",
    "sequence_8 = ''  #@param {type:\"string\"}\n",
    "sequence_9 = ''  #@param {type:\"string\"}\n",
    "sequence_10 = ''  #@param {type:\"string\"}\n",
    "sequence_11 = ''  #@param {type:\"string\"}\n",
    "sequence_12 = ''  #@param {type:\"string\"}\n",
    "sequence_13 = ''  #@param {type:\"string\"}\n",
    "sequence_14 = ''  #@param {type:\"string\"}\n",
    "sequence_15 = ''  #@param {type:\"string\"}\n",
    "sequence_16 = ''  #@param {type:\"string\"}\n",
    "sequence_17 = ''  #@param {type:\"string\"}\n",
    "sequence_18 = ''  #@param {type:\"string\"}\n",
    "sequence_19 = ''  #@param {type:\"string\"}\n",
    "sequence_20 = ''  #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Downloads the latest refseq assembly summary if not already downloaded\n",
    "if not os.path.exists(\"assembly_summary_refseq.txt\"):\n",
    "    urllib.request.urlretrieve(\"https://ftp.ncbi.nlm.nih.gov/genomes/ASSEMBLY_REPORTS/assembly_summary_refseq.txt\", \"assembly_summary_refseq.txt\")\n",
    "\n",
    "genus, species = input(\"Please enter a desired species.\\nEx: Homo sapiens\").split(\" \")\n",
    "\n",
    "# Retrieves link from refseq db\n",
    "with open(\"assembly_summary_refseq.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if genus in line and species in line:\n",
    "            link = line.split(\"\\t\")[19]\n",
    "            break\n",
    "    else:\n",
    "        print(f\"No matches found for {genus} {species}\")\n",
    "\n",
    "# Generates directory\n",
    "g = genus[0]\n",
    "new_dir = f\"{g}_{species}\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "# Gets file name\n",
    "file_name = link.split(\"/\")[-1] + \"_genomic.fna.gz\"\n",
    "\n",
    "# Gets fna download link\n",
    "fna = f\"{link}/{file_name}\"\n",
    "\n",
    "# Downloads, moves, and unzips file\n",
    "urllib.request.urlretrieve(fna, os.path.join(new_dir, file_name))\n",
    "os.system(f\"gunzip {os.path.join(new_dir, file_name)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Must specify at least two fasta files for comparison\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python3\n",
    "\n",
    "import argparse, Bio.SeqIO, math, re\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import pstdev\n",
    "\n",
    "# parses command-line arguments with fasta files, kmer size, and an output file\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"K-mer Based Distance Estimation\")\n",
    "    parser.add_argument(\"fasta\", nargs=\"+\", help=\"fasta files containing nucleic acid sequences\")\n",
    "    parser.add_argument(\"-k\", type=int, default=1, help=\"k-mer size\")\n",
    "    parser.add_argument(\"-m\", action=\"store_true\", \n",
    "        help=\"if specified, returns mahalanobis distance; defaults to euclidean distance\")\n",
    "    parser.add_argument(\"-n\", action=\"store_true\", \n",
    "        help=\"if specified, normalizes distance to percentage, and generates heatmap\")\n",
    "    parser.add_argument(\"--out\", \"-o\", help=\"kmer data table output\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "# generates kmer dictionary from fasta formatted data\n",
    "def parse_fasta(fasta, k):\n",
    "    kmer_dict = {}\n",
    "\n",
    "    # parses fasta file using SeqRecord iterator\n",
    "    for record in Bio.SeqIO.parse(fasta, \"fasta\"):\n",
    "        seq = record.seq\n",
    "        regex = \"([A-Z])[a-z]+(( [a-z]+)+ ?[1-9]?)\"\n",
    "        match = re.search(regex, record.description)\n",
    "        genus = match.group(1)\n",
    "        species = match.group(2)\n",
    "        organism = genus + \".\" + species\n",
    "\n",
    "        # Iterates over all combinations of k continuous nucleotides and adds the kmers to\n",
    "        # a dictionary with a counter of the number of instances of the kmers\n",
    "        for nuc_idx in range(len(seq) - (k - 1)):\n",
    "            kmer = seq[nuc_idx:(nuc_idx + k)]\n",
    "            kmer_dict.setdefault(kmer, 0)\n",
    "            kmer_dict[kmer] += 1\n",
    "            \n",
    "    print(\"Parsed {0} -------> Exracted Organism: {1}\".format(fasta, organism))\n",
    "    return (organism, kmer_dict)\n",
    "\n",
    "# compares the keys in two dictionaries, and adds the missing keys\n",
    "# from each into one another\n",
    "def compare_kmer(dict_1, dict_2):\n",
    "    set_1 = set(dict_1.keys())\n",
    "    set_2 = set(dict_2.keys())\n",
    "    diff_keys = list(set_1.symmetric_difference(set_2))\n",
    "    for key in diff_keys:\n",
    "        dict_1.setdefault(key, 0)\n",
    "        dict_2.setdefault(key, 0)\n",
    "\n",
    "# computes euclidean distance based on two kmer dictionaries\n",
    "def euclid_kmer(dict_1, dict_2):\n",
    "    euclid_sum = 0\n",
    "    for coord in dict_2:\n",
    "        euclid_sum += (dict_2[coord] - dict_1[coord])**2\n",
    "    return math.sqrt(euclid_sum)\n",
    "\n",
    "# computes mahalanobis distance based on two kmer dictionaries\n",
    "def maha_kmer(dict_1, dict_2):\n",
    "    maha_sum = 0\n",
    "    for coord in dict_2:\n",
    "        # calculates stdev from two kmer coordinates\n",
    "        dev = pstdev((dict_2[coord], dict_1[coord]))\n",
    "        if dev == 0:\n",
    "            continue\n",
    "        maha_sum += ((dict_2[coord]/dev) - (dict_1[coord]/dev))**2\n",
    "    return math.sqrt(maha_sum)\n",
    "\n",
    "# normalizes distances in the output matrix to 1\n",
    "def normalize(distances):\n",
    "    all_values = []\n",
    "    for sub in distances:\n",
    "        for val in sub:\n",
    "            all_values.append(val)\n",
    "\n",
    "    minimum = min(all_values)\n",
    "    maximum = max(all_values)\n",
    "\n",
    "    # sets values in sub_lists to normalized values\n",
    "    for sub in distances:\n",
    "        for idx, val in enumerate(sub):\n",
    "            norm_val = (val - minimum)/(maximum - minimum)\n",
    "            sub[idx] = norm_val\n",
    "\n",
    "    return distances\n",
    "\n",
    "def matrix_output(samples, k, maha):\n",
    "    ### {sample_N: {sample_N kmer dict}, ...} ###\n",
    "    distance_dict = {}\n",
    "    orgs = []\n",
    "\n",
    "    # pairs kmer dictionaries with organism names\n",
    "    for sample in samples:\n",
    "        org, distance_dict[sample] = parse_fasta(sample, k)\n",
    "        # adds organism to list for output header\n",
    "        if org not in orgs:\n",
    "                orgs.append(org)\n",
    "\n",
    "    ### {(sample_x, sample_y): dist, ...} ###\n",
    "    # stores previously computed distance values so program only\n",
    "    # has to run unique pairs of orgs\n",
    "    store_compare = {}\n",
    "\n",
    "    # distance matrix output; list of lists\n",
    "    distances = []\n",
    "    for sample_1 in samples:\n",
    "        sub_dist = []\n",
    "        for sample_2 in samples:\n",
    "            # if distance already computed, grab cached value\n",
    "            if (sample_2, sample_1) in store_compare:\n",
    "                sub_dist.append(store_compare[sample_2, sample_1])\n",
    "                continue\n",
    "            # if samples are the same, dist = 0\n",
    "            if sample_1 == sample_2:\n",
    "                sub_dist.append(0.00)\n",
    "                continue\n",
    "\n",
    "            # grabs kmer dictionaries from distance_dict\n",
    "            kmer_1 = distance_dict[sample_1]\n",
    "            kmer_2 = distance_dict[sample_2]\n",
    "\n",
    "            compare_kmer(kmer_1, kmer_2)\n",
    "            # calculates distance using eithe mahalanobis distance or euclidean\n",
    "            # distance based on command-line input\n",
    "            dist = maha_kmer(kmer_1, kmer_2) if maha else euclid_kmer(kmer_1, kmer_2)\n",
    "            # adds dist to cache dictionary\n",
    "            store_compare[(sample_1, sample_2)] = dist\n",
    "            sub_dist.append(dist)\n",
    "\n",
    "        distances.append(sub_dist)\n",
    "    return orgs, distances\n",
    "\n",
    "def make_table(k, norm, orgs, distances, output):\n",
    "    # normalizes the data in distances if user specifies\n",
    "    if norm:\n",
    "        distances = normalize(distances)\n",
    "\n",
    "    # if data is not normalized, generates a tab-separated output file\n",
    "    else:\n",
    "        out_data = (\"{0}-mer comparison\\t{1}\\n\".format(k, (\"\\t\").join(orgs)))\n",
    "        for idx, org in enumerate(orgs):\n",
    "            out_data += (\"{0}\\t{1}\\n\".format(org, (\"\\t\").join(str(dist) for dist in distances[idx])))\n",
    "        # writes data to output file if specified\n",
    "        if output is not None:\n",
    "            try:\n",
    "                with open(output + \".txt\", \"w\") as out_file:\n",
    "                    out_file.write(out_data)\n",
    "                    print(\"Distance matrix saved to {0}.txt\".format(output))\n",
    "            except IOError:\n",
    "                print(\"Error writing to file\")\n",
    "            return\n",
    "        # prints to standard out otherwise\n",
    "        else:\n",
    "            print(out_data)\n",
    "            return\n",
    "\n",
    "    # generates a heatmap based on orgaism similarity\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set_xticks(range(len(orgs))); ax.set_yticks(range(len(orgs)))\n",
    "    ax.set_xticklabels(orgs); ax.set_yticklabels(orgs)\n",
    "    ax.set_title(\"{0}-mer Distance Estimation\".format(k))\n",
    "\n",
    "    # adds value from distance matrix to correct square\n",
    "    # only used on small datasets to prevent formatting errors\n",
    "    if len(orgs) <= 10:\n",
    "        for org_1 in range(len(orgs)):\n",
    "            for org_2 in range(len(orgs)):\n",
    "                data = ax.text(org_1, org_2, str(round(distances[org_1][org_2], 2)),\n",
    "                    ha=\"center\", va=\"center\", color=\"w\", fontsize=16)\n",
    "\n",
    "    # creates heatmap from axes and matrix\n",
    "    ax.xaxis.tick_top()\n",
    "    heatmap = ax.imshow(distances, cmap=\"RdBu\")\n",
    "    fig.colorbar(heatmap)\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", \n",
    "        va=\"top\", rotation_mode=\"anchor\", fontsize=10)\n",
    "\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=10)\n",
    "\n",
    "    fig.set_size_inches(10, 8)\n",
    "    plt.savefig(output + \".jpg\", bbox_inches=\"tight\")\n",
    "    print(\"Heatmap saved to {0}.jpg\".format(output))\n",
    "\n",
    "\n",
    "#orgs, distances = matrix_output(args.fasta, args.k, args.m)\n",
    "#make_table(args.k, args.n, orgs, distances, args.out)\n",
    "\n",
    "print(\"Must specify at least two fasta files for comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
